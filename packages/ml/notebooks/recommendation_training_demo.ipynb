{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Training & Evaluation\n",
    "\n",
    "This notebook demonstrates how to train and evaluate the ALS + TF-IDF hybrid recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import csr_matrix\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from app.db import db\n",
    "from app.config import settings\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load orders\n",
    "orders_df = db.get_all_orders()\n",
    "print(f\"Total orders: {len(orders_df)}\")\n",
    "print(f\"Unique users: {orders_df['user_id'].nunique()}\")\n",
    "print(f\"Unique products: {orders_df['product_id'].nunique()}\")\n",
    "\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load products\n",
    "products_df = db.get_products()\n",
    "print(f\"Total products: {len(products_df)}\")\n",
    "\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order distribution per user\n",
    "user_order_counts = orders_df.groupby('user_id').size()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(user_order_counts, bins=30, edgecolor='black')\n",
    "plt.xlabel('Number of Orders')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.title('Distribution of Orders per User')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "product_order_counts = orders_df.groupby('product_id').size()\n",
    "plt.hist(product_order_counts, bins=30, edgecolor='black')\n",
    "plt.xlabel('Number of Orders')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.title('Distribution of Orders per Product')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average orders per user: {user_order_counts.mean():.2f}\")\n",
    "print(f\"Average orders per product: {product_order_counts.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "products_df['category'].value_counts().head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Product Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert quantity to implicit feedback\n",
    "orders_df['weight'] = orders_df['quantity'].apply(lambda x: min(x, 10))\n",
    "\n",
    "# Aggregate by user-product pairs\n",
    "interactions = orders_df.groupby(['user_id', 'product_id'])['weight'].sum().reset_index()\n",
    "\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "user_ids = sorted(interactions['user_id'].unique())\n",
    "item_ids = sorted(interactions['product_id'].unique())\n",
    "\n",
    "user_index = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "item_index = {pid: idx for idx, pid in enumerate(item_ids)}\n",
    "\n",
    "print(f\"Users: {len(user_ids)}\")\n",
    "print(f\"Items: {len(item_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sparse matrix\n",
    "rows = interactions['user_id'].map(user_index).values\n",
    "cols = interactions['product_id'].map(item_index).values\n",
    "data = interactions['weight'].values\n",
    "\n",
    "user_item_matrix = csr_matrix(\n",
    "    (data, (rows, cols)),\n",
    "    shape=(len(user_ids), len(item_ids))\n",
    ")\n",
    "\n",
    "sparsity = 1 - (user_item_matrix.nnz / (user_item_matrix.shape[0] * user_item_matrix.shape[1]))\n",
    "\n",
    "print(f\"Matrix shape: {user_item_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {user_item_matrix.nnz}\")\n",
    "print(f\"Sparsity: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize matrix sparsity\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.spy(user_item_matrix[:100, :100], markersize=1)\n",
    "plt.title('User-Item Matrix Sparsity (first 100x100)')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ALS model\n",
    "als_model = AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.01,\n",
    "    iterations=20,\n",
    "    calculate_training_loss=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training ALS model...\")\n",
    "als_model.fit(user_item_matrix, show_progress=True)\n",
    "print(\"✓ Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample recommendations\n",
    "sample_user_id = user_ids[0]\n",
    "sample_user_idx = user_index[sample_user_id]\n",
    "\n",
    "print(f\"Sample recommendations for user {sample_user_id}:\")\n",
    "\n",
    "ids, scores = als_model.recommend(\n",
    "    sample_user_idx,\n",
    "    user_item_matrix[sample_user_idx],\n",
    "    N=10,\n",
    "    filter_already_liked_items=True\n",
    ")\n",
    "\n",
    "index_to_item = {idx: iid for iid, idx in item_index.items()}\n",
    "\n",
    "for idx, score in zip(ids, scores):\n",
    "    product_id = index_to_item[idx]\n",
    "    print(f\"  Product {product_id}: score {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text features\n",
    "products_df['text'] = (\n",
    "    products_df['title'].fillna('') + ' ' + \n",
    "    products_df['description'].fillna('') + ' ' + \n",
    "    products_df['category'].fillna('')\n",
    ")\n",
    "\n",
    "# Train TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(products_df['text'].values)\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test content-based recommendations\n",
    "sample_product_idx = 0\n",
    "sample_product = products_df.iloc[sample_product_idx]\n",
    "\n",
    "print(f\"Similar products to: {sample_product['title']}\\n\")\n",
    "\n",
    "similarities = cosine_similarity(tfidf_matrix[sample_product_idx:sample_product_idx+1], tfidf_matrix).flatten()\n",
    "similar_indices = similarities.argsort()[::-1][1:11]  # Top 10, excluding itself\n",
    "\n",
    "for idx in similar_indices:\n",
    "    print(f\"  {products_df.iloc[idx]['title']}: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_recommendations(user_id, top_k=10):\n",
    "    \"\"\"Get collaborative filtering recommendations.\"\"\"\n",
    "    if user_id not in user_index:\n",
    "        return []\n",
    "    \n",
    "    user_idx = user_index[user_id]\n",
    "    ids, scores = als_model.recommend(\n",
    "        user_idx,\n",
    "        user_item_matrix[user_idx],\n",
    "        N=top_k,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    \n",
    "    return [(index_to_item[idx], float(score)) for idx, score in zip(ids, scores)]\n",
    "\n",
    "def get_cb_recommendations(user_id, top_k=10):\n",
    "    \"\"\"Get content-based recommendations.\"\"\"\n",
    "    # Get user's purchased products\n",
    "    user_products = interactions[interactions['user_id'] == user_id]['product_id'].tolist()\n",
    "    \n",
    "    if not user_products:\n",
    "        return []\n",
    "    \n",
    "    # Get product indices\n",
    "    product_indices = []\n",
    "    for prod_id in user_products:\n",
    "        idx_list = products_df.index[products_df['id'] == prod_id].tolist()\n",
    "        if idx_list:\n",
    "            product_indices.append(idx_list[0])\n",
    "    \n",
    "    if not product_indices:\n",
    "        return []\n",
    "    \n",
    "    # Create user profile\n",
    "    user_profile = tfidf_matrix[product_indices].mean(axis=0)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(user_profile, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get top N (excluding already purchased)\n",
    "    recommendations = []\n",
    "    for idx in similarities.argsort()[::-1]:\n",
    "        product_id = products_df.iloc[idx]['id']\n",
    "        if product_id not in user_products:\n",
    "            recommendations.append((product_id, float(similarities[idx])))\n",
    "            if len(recommendations) >= top_k:\n",
    "                break\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def get_hybrid_recommendations(user_id, top_k=10, cf_weight=0.7, cb_weight=0.3):\n",
    "    \"\"\"Get hybrid recommendations.\"\"\"\n",
    "    cf_recs = get_cf_recommendations(user_id, top_k * 2)\n",
    "    cb_recs = get_cb_recommendations(user_id, top_k * 2)\n",
    "    \n",
    "    # Combine scores\n",
    "    combined = {}\n",
    "    \n",
    "    for prod_id, score in cf_recs:\n",
    "        combined[prod_id] = score * cf_weight\n",
    "    \n",
    "    for prod_id, score in cb_recs:\n",
    "        if prod_id in combined:\n",
    "            combined[prod_id] += score * cb_weight\n",
    "        else:\n",
    "            combined[prod_id] = score * cb_weight\n",
    "    \n",
    "    # Sort and return top K\n",
    "    sorted_recs = sorted(combined.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_recs[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods for a sample user\n",
    "test_user = user_ids[0]\n",
    "\n",
    "print(f\"Recommendations for user {test_user}:\\n\")\n",
    "\n",
    "print(\"Collaborative Filtering:\")\n",
    "cf_recs = get_cf_recommendations(test_user, 5)\n",
    "for prod_id, score in cf_recs:\n",
    "    print(f\"  {prod_id}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nContent-Based:\")\n",
    "cb_recs = get_cb_recommendations(test_user, 5)\n",
    "for prod_id, score in cb_recs:\n",
    "    print(f\"  {prod_id}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nHybrid (0.7 CF + 0.3 CB):\")\n",
    "hybrid_recs = get_hybrid_recommendations(test_user, 5)\n",
    "for prod_id, score in hybrid_recs:\n",
    "    print(f\"  {prod_id}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage analysis\n",
    "all_recommended = set()\n",
    "\n",
    "for user_id in user_ids[:50]:  # Sample 50 users\n",
    "    recs = get_hybrid_recommendations(user_id, 10)\n",
    "    all_recommended.update([prod_id for prod_id, _ in recs])\n",
    "\n",
    "coverage = len(all_recommended) / len(item_ids)\n",
    "print(f\"Catalog coverage: {coverage:.2%}\")\n",
    "print(f\"Unique products recommended: {len(all_recommended)} out of {len(item_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distribution\n",
    "all_scores = []\n",
    "\n",
    "for user_id in user_ids[:50]:\n",
    "    recs = get_hybrid_recommendations(user_id, 10)\n",
    "    all_scores.extend([score for _, score in recs])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_scores, bins=30, edgecolor='black')\n",
    "plt.xlabel('Recommendation Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Recommendation Scores')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean score: {np.mean(all_scores):.4f}\")\n",
    "print(f\"Median score: {np.median(all_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALS model\n",
    "als_path = settings.model_dir / \"als_model.joblib\"\n",
    "joblib.dump(als_model, als_path)\n",
    "print(f\"✓ ALS model saved to {als_path}\")\n",
    "\n",
    "# Save TF-IDF model\n",
    "tfidf_path = settings.model_dir / \"tfidf.joblib\"\n",
    "joblib.dump({\n",
    "    'vectorizer': tfidf,\n",
    "    'matrix': tfidf_matrix,\n",
    "    'products': products_df[['id', 'title', 'description', 'category', 'text']]\n",
    "}, tfidf_path)\n",
    "print(f\"✓ TF-IDF model saved to {tfidf_path}\")\n",
    "\n",
    "# Save mappings\n",
    "mappings_path = settings.model_dir / \"mappings.json\"\n",
    "mappings = {\n",
    "    'user_index': user_index,\n",
    "    'item_index': item_index,\n",
    "    'user_ids': user_ids,\n",
    "    'item_ids': item_ids,\n",
    "    'index_to_user': {str(idx): uid for uid, idx in user_index.items()},\n",
    "    'index_to_item': {str(idx): iid for iid, idx in item_index.items()}\n",
    "}\n",
    "\n",
    "with open(mappings_path, 'w') as f:\n",
    "    json.dump(mappings, f, indent=2)\n",
    "print(f\"✓ Mappings saved to {mappings_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test API\n",
    "\n",
    "Now you can start the ML service and test the API:\n",
    "\n",
    "```bash\n",
    "# In terminal\n",
    "python -m app.main\n",
    "\n",
    "# In another terminal\n",
    "curl \"http://localhost:8000/recommendations/user/USER_ID?top_k=10\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with requests (if service is running)\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f'http://localhost:8000/recommendations/user/{test_user}?top_k=5')\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"API Response:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "    else:\n",
    "        print(f\"API returned status {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"ML service not running. Start it with: python -m app.main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and exploring order/product data\n",
    "2. Building user-item interaction matrix\n",
    "3. Training ALS collaborative filtering model\n",
    "4. Training TF-IDF content-based model\n",
    "5. Implementing hybrid recommendations\n",
    "6. Analyzing recommendation quality\n",
    "7. Saving models for production use\n",
    "\n",
    "Next steps:\n",
    "- Tune hyperparameters (factors, regularization, weights)\n",
    "- Implement evaluation metrics (precision@K, recall@K, NDCG)\n",
    "- A/B test different approaches\n",
    "- Monitor performance in production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
